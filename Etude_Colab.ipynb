{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "# Etude - Piano Cover Generation\n",
        "\n",
        "This notebook allows you to run the Etude pipeline directly from Google Drive.\n",
        "\n",
        "## Setup\n",
        "\n",
        "1.  **Mount Google Drive**: This allows the notebook to access your files.\n",
        "2.  **Install Dependencies**: Installs the necessary libraries (Demucs, PyTorch, Madmom, etc.).\n",
        "3.  **Download Models**: Downloads the pre-trained checkpoints required for inference.\n",
        "4.  **Navigate to Project**: Changes the working directory to where you cloned/uploaded the Etude repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount-drive"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "change-dir"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Change this path to match where you uploaded/cloned the Etude folder in your Drive.\n",
        "# Example: '/content/drive/MyDrive/Projects/Etude'\n",
        "PROJECT_PATH = '/content/drive/MyDrive/Etude'\n",
        "# ---------------------\n",
        "\n",
        "if not os.path.exists(PROJECT_PATH):\n",
        "    print(f\"WARNING: Path {PROJECT_PATH} does not exist. Please check your Drive structure.\")\n",
        "else:\n",
        "    os.chdir(PROJECT_PATH)\n",
        "    print(f\"Current working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install-deps-header"
      },
      "source": [
        "## Install Dependencies\n",
        "We need to install system libraries (ffmpeg) and Python packages.\n",
        "\n",
        "**Note on Dependencies:**\n",
        "The `synctoolbox` library requires `numpy<2.0` and `pandas<2.0`. We explicitly install these older versions to ensure compatibility. This might cause pip to show warnings about `google-colab` or other pre-installed packages being incompatible, but this is expected and necessary for the audio processing pipeline to work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-system-deps"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update && sudo apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-build-deps"
      },
      "outputs": [],
      "source": [
        "# Ensure Cython is available for building madmom, but don't force a version.\n",
        "!pip install Cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-reqs"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "patch-madmom"
      },
      "outputs": [],
      "source": [
        "# Install Madmom from source with patching\n",
        "# We clone the repo, patch the source code (fixing np.int/np.float issues), and then install.\n",
        "# This ensures the Cython extensions are compiled with the correct NumPy types.\n",
        "\n",
        "import os\n",
        "if not os.path.exists('madmom'):\n",
        "    !git clone https://github.com/CPJKU/madmom.git\n",
        "\n",
        "# Run the patch script on the SOURCE directory\n",
        "!python fix_madmom.py --path madmom\n",
        "\n",
        "# Install from the patched source\n",
        "!pip install ./madmom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check-versions"
      },
      "outputs": [],
      "source": [
        "# Verify PyTorch versions\n",
        "import torch\n",
        "import torchvision\n",
        "import torchaudio\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Torchvision version: {torchvision.__version__}\")\n",
        "print(f\"Torchaudio version: {torchaudio.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download-models-header"
      },
      "source": [
        "## Download Pre-trained Models\n",
        "This step downloads the necessary model checkpoints and extracts them to the `checkpoints/` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download-models"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('checkpoints'):\n",
        "    print(\"Downloading checkpoints...\")\n",
        "    !wget -O checkpoints.zip \"https://github.com/Xiugapurin/Etude/releases/download/latest/checkpoints.zip\"\n",
        "    !unzip -q checkpoints.zip\n",
        "    !rm checkpoints.zip\n",
        "    print(\"Checkpoints downloaded and extracted.\")\n",
        "else:\n",
        "    print(\"Checkpoints directory already exists. Skipping download.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pipeline-header"
      },
      "source": [
        "## Run Pipeline\n",
        "\n",
        "You can now run the data preparation or inference scripts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inference-header"
      },
      "source": [
        "### Inference (Generate Piano Cover)\n",
        "Use `infer.py` to generate a cover from a YouTube URL or local file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run-inference"
      },
      "outputs": [],
      "source": [
        "# Example: Generate a cover from a YouTube URL\n",
        "# Replace the URL with your desired song.\n",
        "!python infer.py --input \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" --output_name \"my_cover\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "resume-header"
      },
      "source": [
        "### Resuming from a Crash\n",
        "If the pipeline crashes (e.g., during Stage 2), you can resume from a specific stage using `--start-from`.\n",
        "\n",
        "- `extract`: Start from beginning (Stage 1)\n",
        "- `structuralize`: Start from Stage 2 (skips extraction)\n",
        "- `decode`: Start from Stage 3 (skips extraction and beat detection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run-resume"
      },
      "outputs": [],
      "source": [
        "# Example: Resume from Stage 2 (Structuralize)\n",
        "# !python infer.py --input \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" --output_name \"my_cover\" --start-from structuralize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training-header"
      },
      "source": [
        "### Data Preparation (Optional)\n",
        "If you are training the model, use `prepare.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run-prepare"
      },
      "outputs": [],
      "source": [
        "!python prepare.py --start-from download"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}