{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "# Etude - Piano Cover Generation\n",
        "\n",
        "This notebook allows you to run the Etude pipeline directly from Google Drive.\n",
        "\n",
        "## Setup\n",
        "\n",
        "1.  **Mount Google Drive**: This allows the notebook to access your files.\n",
        "2.  **Install Dependencies**: Installs the necessary libraries (Demucs, PyTorch, Madmom, etc.).\n",
        "3.  **Download Models**: Downloads the pre-trained checkpoints required for inference.\n",
        "4.  **Navigate to Project**: Changes the working directory to where you cloned/uploaded the Etude repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount-drive"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "change-dir"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Change this path to match where you uploaded/cloned the Etude folder in your Drive.\n",
        "# Example: '/content/drive/MyDrive/Projects/Etude'\n",
        "PROJECT_PATH = '/content/drive/MyDrive/Etude'\n",
        "# ---------------------\n",
        "\n",
        "if not os.path.exists(PROJECT_PATH):\n",
        "    print(f\"WARNING: Path {PROJECT_PATH} does not exist. Please check your Drive structure.\")\n",
        "else:\n",
        "    os.chdir(PROJECT_PATH)\n",
        "    print(f\"Current working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install-deps-header"
      },
      "source": [
        "## Install Dependencies\n",
        "We need to install system libraries (ffmpeg) and Python packages.\n",
        "We allow Colab's pre-installed libraries (like NumPy, PyTorch) to take precedence to avoid conflicts, but ensure torchvision matches torch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-system-deps"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update && sudo apt-get install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-build-deps"
      },
      "outputs": [],
      "source": [
        "# Ensure Cython is available for building madmom, but don't force a version.\n",
        "!pip install Cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-reqs"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check-versions"
      },
      "outputs": [],
      "source": [
        "# Verify PyTorch versions\n",
        "import torch\n",
        "import torchvision\n",
        "import torchaudio\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Torchvision version: {torchvision.__version__}\")\n",
        "print(f\"Torchaudio version: {torchaudio.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download-models-header"
      },
      "source": [
        "## Download Pre-trained Models\n",
        "This step downloads the necessary model checkpoints and extracts them to the `checkpoints/` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download-models"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('checkpoints'):\n",
        "    print(\"Downloading checkpoints...\")\n",
        "    !wget -O checkpoints.zip \"https://github.com/Xiugapurin/Etude/releases/download/latest/checkpoints.zip\"\n",
        "    !unzip -q checkpoints.zip\n",
        "    !rm checkpoints.zip\n",
        "    print(\"Checkpoints downloaded and extracted.\")\n",
        "else:\n",
        "    print(\"Checkpoints directory already exists. Skipping download.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pipeline-header"
      },
      "source": [
        "## Run Pipeline\n",
        "\n",
        "You can now run the data preparation or inference scripts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inference-header"
      },
      "source": [
        "### Inference (Generate Piano Cover)\n",
        "Use `infer.py` to generate a cover from a YouTube URL or local file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run-inference"
      },
      "outputs": [],
      "source": [
        "# Example: Generate a cover from a YouTube URL\n",
        "# Replace the URL with your desired song.\n",
        "!python infer.py --input \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" --output_name \"my_cover\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training-header"
      },
      "source": [
        "### Data Preparation (Optional)\n",
        "If you are training the model, use `prepare.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run-prepare"
      },
      "outputs": [],
      "source": [
        "!python prepare.py --start-from download"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}